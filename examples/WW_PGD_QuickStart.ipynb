{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CalculatedContent/WW_PGD/blob/main/WW_PGD_QuickStart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lx6HuqxpkM",
        "outputId": "12e9ca8d-9d6b-49ed-ea96-02faa019de72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WW_PGD'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 43 (delta 17), reused 34 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (43/43), 10.20 KiB | 10.20 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CalculatedContent/WW_PGD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip uninstall -y ww_pgd\n",
        "!{sys.executable} -m pip install -e /content/WW_PGD\n",
        "import ww_pgd\n",
        "print(\"Imported from:\", ww_pgd.__file__)"
      ],
      "metadata": {
        "id": "NsXe-xSXQfR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QuickStart (trivial example)"
      ],
      "metadata": {
        "id": "0jpFBEEriacj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import ww_pgd\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Data loader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_ds = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = nn.Linear(28 * 28, 10).to(device)\n",
        "\n",
        "# Optimizers\n",
        "base_opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "cfg = ww_pgd.WWTailConfig(warmup_epochs=0, ramp_epochs=5)\n",
        "opt = ww_pgd.WWPGDWrapper(model, base_opt, cfg)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = xb.view(xb.size(0), -1)  # flatten\n",
        "\n",
        "        loss = F.cross_entropy(model(xb), yb)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    # epoch-boundary spectral projection\n",
        "    opt.apply_tail_projection(epoch=epoch, num_epochs=num_epochs)\n",
        "    print(f\"epoch {epoch+1}/{num_epochs} done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "o7WUAZ6PPNTs",
        "outputId": "ba6f8e98-56da-42c9-95a7-fe9287dfebc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1085114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JPEG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_interface__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# numpy array interface support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weightwatcher as ww\n",
        "watcher = ww.WeightWatcher(model=model)\n",
        "details = watcher.analyze(detX=True, randomize=False, plot=True)\n",
        "details"
      ],
      "metadata": {
        "id": "kH9n7HgpXwVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PBffoDcJPNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Test: Train a 3-layer MLP on FashionMNIST"
      ],
      "metadata": {
        "id": "HksHDjaHZwto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# COMPLETE WORKING COLAB CELL (MNIST)\n",
        "# 5x Baseline vs 5x ww_pgd on MNIST (35 epochs)\n",
        "# Logs + plots: plain-test AND augmented-test accuracy per epoch\n",
        "# Plus WW metric plots (alpha/xmin/detX_num + detX_num - num_pl_spikes)\n",
        "# ======================================================\n",
        "\n",
        "# If you're using a local editable install already, you can comment these out.\n",
        "!pip -q install weightwatcher\n",
        "# If ww_pgd is not installed in your Colab kernel yet, uncomment:\n",
        "# !pip -q install git+https://github.com/CalculatedContent/WW_PGD.git\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "import weightwatcher as ww\n",
        "import ww_pgd\n",
        "\n",
        "# -----------------------------\n",
        "# Global experiment config\n",
        "# -----------------------------\n",
        "NUM_EPOCHS = 35\n",
        "N_RUNS = 5\n",
        "\n",
        "# -----------------------------\n",
        "# Device\n",
        "# -----------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "pin_memory = device == \"cuda\"\n",
        "num_workers = 2\n",
        "\n",
        "# -----------------------------\n",
        "# MNIST dataset + DataLoaders\n",
        "# -----------------------------\n",
        "batch_size = 128\n",
        "\n",
        "plain_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True,  download=True, transform=plain_transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=plain_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "# Augmented evaluation transform (mild, in-distribution for MNIST)\n",
        "# NOTE: No horizontal flip for digits.\n",
        "aug_eval_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(7),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.03, 0.03)),\n",
        "    transforms.GaussianBlur(3, sigma=(0.1, 0.3)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_aug_ds = datasets.MNIST(root=\"./data\", train=False, download=True, transform=aug_eval_transform)\n",
        "test_aug_loader = DataLoader(test_aug_ds, batch_size=batch_size, shuffle=False,\n",
        "                             num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation\n",
        "# -----------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb, reduction=\"sum\")\n",
        "        total_loss += loss.item()\n",
        "        preds = logits.argmax(dim=-1)\n",
        "        total_correct += (preds == yb).sum().item()\n",
        "        total_samples += yb.size(0)\n",
        "    return total_loss / total_samples, total_correct / total_samples\n",
        "\n",
        "# -----------------------------\n",
        "# 3-layer MLP\n",
        "# -----------------------------\n",
        "class MLP3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 512),  # FC1\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),    # FC2\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),     # FC3\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# -----------------------------\n",
        "# WeightWatcher logging\n",
        "# -----------------------------\n",
        "def log_weightwatcher(model, epoch: int) -> pd.DataFrame:\n",
        "    watcher = ww.WeightWatcher(model=model)\n",
        "    details = watcher.analyze(detX=True, randomize=False, plot=False)\n",
        "    details[\"epoch_id\"] = epoch\n",
        "    return details\n",
        "\n",
        "# -----------------------------\n",
        "# Single run (baseline or ww_pgd)\n",
        "# -----------------------------\n",
        "def train_one_run(run_id: int, use_ww_pgd: bool, num_epochs: int = NUM_EPOCHS):\n",
        "    torch.manual_seed(123 + run_id)\n",
        "    np.random.seed(123 + run_id)\n",
        "\n",
        "    model = MLP3().to(device)\n",
        "    base_optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "    ww_logs_local: List[pd.DataFrame] = []\n",
        "\n",
        "    if use_ww_pgd:\n",
        "        cfg = ww_pgd.WWTailConfig(\n",
        "            enable_tail_pgd=True,\n",
        "            min_tail=5,\n",
        "            q=1.0,\n",
        "            blend_eta=0.5,\n",
        "            cayley_eta=0.25,\n",
        "            use_detx=True,\n",
        "            warmup_epochs=0,\n",
        "            ramp_epochs=5,\n",
        "            enable_trap_pgd=False,\n",
        "            trap_blend_eta=0.5,\n",
        "            trap_tw_k=2.0,\n",
        "            trap_min_spikes=1,\n",
        "            verbose=False,\n",
        "        )\n",
        "        opt = ww_pgd.WWPGDWrapper(\n",
        "            model=model,\n",
        "            base_optimizer=base_optimizer,\n",
        "            tail_config=cfg,\n",
        "            apply_every_epochs=1,\n",
        "            ww_logs=None,  # logging separately below\n",
        "        )\n",
        "        ww_opt = opt\n",
        "    else:\n",
        "        opt = base_optimizer\n",
        "        ww_opt = None\n",
        "\n",
        "    mode = \"ww_pgd\" if use_ww_pgd else \"baseline\"\n",
        "    print(f\"\\n[Run {run_id}] Mode={mode}\")\n",
        "\n",
        "    test_accs = []\n",
        "    aug_accs  = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            logits = model(xb)\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "\n",
        "            # optimizer API compatibility\n",
        "            if hasattr(opt, \"zero_grad\"):\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "            else:\n",
        "                base_optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            if hasattr(opt, \"step\"):\n",
        "                opt.step()\n",
        "            else:\n",
        "                base_optimizer.step()\n",
        "\n",
        "        # Apply WW-PGD at epoch boundary (requires num_epochs)\n",
        "        if use_ww_pgd and ww_opt is not None:\n",
        "            ww_opt.apply_tail_projection(epoch=epoch, num_epochs=num_epochs)\n",
        "\n",
        "        # Log WW metrics\n",
        "        ww_details = log_weightwatcher(model, epoch=epoch)\n",
        "        ww_logs_local.append(ww_details)\n",
        "\n",
        "        # Evaluate plain + augmented\n",
        "        _, test_acc = evaluate(model, test_loader)\n",
        "        _, aug_acc  = evaluate(model, test_aug_loader)\n",
        "        test_accs.append(test_acc)\n",
        "        aug_accs.append(aug_acc)\n",
        "\n",
        "        msg = f\"[Run {run_id}][Epoch {epoch+1}/{num_epochs}] Test={test_acc*100:.2f}%, Aug={aug_acc*100:.2f}%\"\n",
        "        print(msg)\n",
        "\n",
        "    return np.array(test_accs), np.array(aug_accs), ww_logs_local\n",
        "\n",
        "# -----------------------------\n",
        "# Run experiments\n",
        "# -----------------------------\n",
        "baseline_runs, baseline_aug_runs, baseline_ww_logs_runs = [], [], []\n",
        "wwpgd_runs,    wwpgd_aug_runs,    wwpgd_ww_logs_runs    = [], [], []\n",
        "\n",
        "print(\"\\n=== Running BASELINE (AdamW) ===\")\n",
        "for r in range(N_RUNS):\n",
        "    accs, aug_accs, wwlogs = train_one_run(run_id=r, use_ww_pgd=False, num_epochs=NUM_EPOCHS)\n",
        "    baseline_runs.append(accs)\n",
        "    baseline_aug_runs.append(aug_accs)\n",
        "    baseline_ww_logs_runs.append(wwlogs)\n",
        "\n",
        "print(\"\\n=== Running WW-PGD (AdamW + ww_pgd) ===\")\n",
        "for r in range(N_RUNS):\n",
        "    accs, aug_accs, wwlogs = train_one_run(run_id=100 + r, use_ww_pgd=True, num_epochs=NUM_EPOCHS)\n",
        "    wwpgd_runs.append(accs)\n",
        "    wwpgd_aug_runs.append(aug_accs)\n",
        "    wwpgd_ww_logs_runs.append(wwlogs)\n",
        "\n",
        "baseline_runs     = np.stack(baseline_runs,     axis=0)\n",
        "baseline_aug_runs = np.stack(baseline_aug_runs, axis=0)\n",
        "wwpgd_runs        = np.stack(wwpgd_runs,        axis=0)\n",
        "wwpgd_aug_runs    = np.stack(wwpgd_aug_runs,    axis=0)\n",
        "\n",
        "epochs = np.arange(1, NUM_EPOCHS + 1)\n",
        "\n",
        "def mean_std(x):\n",
        "    return x.mean(axis=0), x.std(axis=0)\n",
        "\n",
        "baseline_mean, baseline_std = mean_std(baseline_runs)\n",
        "wwpgd_mean,    wwpgd_std    = mean_std(wwpgd_runs)\n",
        "\n",
        "baseline_aug_mean, baseline_aug_std = mean_std(baseline_aug_runs)\n",
        "wwpgd_aug_mean,    wwpgd_aug_std    = mean_std(wwpgd_aug_runs)\n",
        "\n",
        "\n",
        "\n",
        "plot_metric_with_errorbars(alpha_base, alpha_pgd, \"Alpha per Layer (mean ± std)\", \"alpha\")\n",
        "plot_metric_with_errorbars(xmin_base, xmin_pgd, \"xmin per Layer (mean ± std)\", \"xmin\")\n",
        "plot_metric_with_errorbars(detx_base, detx_pgd, \"detX_num per Layer (mean ± std)\", \"detX_num\")\n",
        "plot_metric_with_errorbars(trap_base, trap_pgd, \"detX_num - num_pl_spikes per Layer (mean ± std)\", \"detX_num - num_pl_spikes\")"
      ],
      "metadata": {
        "id": "unMz6iSEPNfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Plot plain test acc\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.errorbar(epochs, baseline_mean*100, yerr=baseline_std*100, marker=\"o\", linestyle=\"-\", capsize=4,\n",
        "             label=\"Baseline (plain)\")\n",
        "plt.errorbar(epochs, wwpgd_mean*100, yerr=wwpgd_std*100, marker=\"o\", linestyle=\"--\", capsize=4,\n",
        "             label=\"ww_pgd (plain)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"MNIST – Plain Test Accuracy (mean ± std)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Plot augmented test acc\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.errorbar(epochs, baseline_aug_mean*100, yerr=baseline_aug_std*100, marker=\"o\", linestyle=\"-\", capsize=4,\n",
        "             label=\"Baseline (aug)\")\n",
        "plt.errorbar(epochs, wwpgd_aug_mean*100, yerr=wwpgd_aug_std*100, marker=\"o\", linestyle=\"--\", capsize=4,\n",
        "             label=\"ww_pgd (aug)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"MNIST – Augmented Test Accuracy (mean ± std)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal (epoch {NUM_EPOCHS}) mean ± std:\")\n",
        "print(f\"Baseline: plain={baseline_mean[-1]*100:.2f}% ± {baseline_std[-1]*100:.2f}%, \"\n",
        "      f\"aug={baseline_aug_mean[-1]*100:.2f}% ± {baseline_aug_std[-1]*100:.2f}%\")\n",
        "print(f\"ww_pgd : plain={wwpgd_mean[-1]*100:.2f}% ± {wwpgd_std[-1]*100:.2f}%, \"\n",
        "      f\"aug={wwpgd_aug_mean[-1]*100:.2f}% ± {wwpgd_aug_std[-1]*100:.2f}%\")\n",
        "\n",
        "# ======================================================\n",
        "# WW metric extraction + plots\n",
        "# ======================================================\n",
        "\n",
        "def extract_metric_paths(ww_logs_runs, num_epochs, metric_name, is_trap=False):\n",
        "    \"\"\"\n",
        "    ww_logs_runs: list[ list[pd.DataFrame] ] per run\n",
        "    returns dict[layer] -> np.array shape (N_RUNS, num_epochs)\n",
        "    \"\"\"\n",
        "    N = len(ww_logs_runs)\n",
        "    layers = [\"FC1\", \"FC2\", \"FC3\"]\n",
        "    layer_paths = {L: np.full((N, num_epochs), np.nan) for L in layers}\n",
        "\n",
        "    for run_idx, wwlogs in enumerate(ww_logs_runs):\n",
        "        ww_all = pd.concat(wwlogs, ignore_index=True)\n",
        "        name_col = \"longname\" if \"longname\" in ww_all.columns else \"name\"\n",
        "        layer_map = {\"net.1\": \"FC1\", \"net.3\": \"FC2\", \"net.5\": \"FC3\"}\n",
        "        ww_all[\"layer\"] = ww_all[name_col].map(layer_map).fillna(ww_all[name_col])\n",
        "\n",
        "        spikes_col = None\n",
        "        if is_trap:\n",
        "            if \"num_pl_spikes\" in ww_all.columns:\n",
        "                spikes_col = \"num_pl_spikes\"\n",
        "            elif \"num_spikes\" in ww_all.columns:\n",
        "                spikes_col = \"num_spikes\"\n",
        "\n",
        "        for L in layers:\n",
        "            for e in range(num_epochs):\n",
        "                df = ww_all[(ww_all[\"layer\"] == L) & (ww_all[\"epoch_id\"] == e)]\n",
        "                if df.empty:\n",
        "                    continue\n",
        "                if is_trap:\n",
        "                    if spikes_col is None or \"detX_num\" not in df.columns:\n",
        "                        continue\n",
        "                    layer_paths[L][run_idx, e] = float((df[\"detX_num\"] - df[spikes_col]).mean())\n",
        "                else:\n",
        "                    if metric_name not in df.columns:\n",
        "                        continue\n",
        "                    layer_paths[L][run_idx, e] = float(df[metric_name].mean())\n",
        "\n",
        "    return layer_paths\n",
        "\n",
        "alpha_base = extract_metric_paths(baseline_ww_logs_runs, NUM_EPOCHS, \"alpha\", is_trap=False)\n",
        "alpha_pgd  = extract_metric_paths(wwpgd_ww_logs_runs,   NUM_EPOCHS, \"alpha\", is_trap=False)\n",
        "\n",
        "xmin_base  = extract_metric_paths(baseline_ww_logs_runs, NUM_EPOCHS, \"xmin\", is_trap=False)\n",
        "xmin_pgd   = extract_metric_paths(wwpgd_ww_logs_runs,   NUM_EPOCHS, \"xmin\", is_trap=False)\n",
        "\n",
        "detx_base  = extract_metric_paths(baseline_ww_logs_runs, NUM_EPOCHS, \"detX_num\", is_trap=False)\n",
        "detx_pgd   = extract_metric_paths(wwpgd_ww_logs_runs,   NUM_EPOCHS, \"detX_num\", is_trap=False)\n",
        "\n",
        "trap_base  = extract_metric_paths(baseline_ww_logs_runs, NUM_EPOCHS, metric_name=None, is_trap=True)\n",
        "trap_pgd   = extract_metric_paths(wwpgd_ww_logs_runs,   NUM_EPOCHS, metric_name=None, is_trap=True)\n",
        "\n",
        "baseline_colors = {\"FC1\":\"#ffb3b3\",\"FC2\":\"#ff6666\",\"FC3\":\"#cc0000\"}\n",
        "pgd_colors      = {\"FC1\":\"#b3d1ff\",\"FC2\":\"#6699ff\",\"FC3\":\"#004c99\"}\n",
        "layers = [\"FC1\",\"FC2\",\"FC3\"]\n",
        "\n",
        "def plot_metric_with_errorbars(metric_base, metric_pgd, title, ylabel):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    for L in layers:\n",
        "        b = metric_base[L]\n",
        "        p = metric_pgd[L]\n",
        "        b_mean, b_std = np.nanmean(b, axis=0), np.nanstd(b, axis=0)\n",
        "        p_mean, p_std = np.nanmean(p, axis=0), np.nanstd(p, axis=0)\n",
        "\n",
        "        plt.errorbar(epochs, b_mean, yerr=b_std, marker=\"o\", linestyle=\"-\", capsize=3,\n",
        "                     color=baseline_colors[L], label=f\"{L} Baseline\")\n",
        "        plt.errorbar(epochs, p_mean, yerr=p_std, marker=\"o\", linestyle=\"--\", capsize=3,\n",
        "                     color=pgd_colors[L], label=f\"{L} ww_pgd\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sgw3ZAYsPLry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHkHF6KNTPgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM0KZt1mhBY6QWTXhCsdS24",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}